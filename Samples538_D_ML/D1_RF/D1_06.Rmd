---
title: "Microbiome model performance on external data"
output: html_document
date: "2024-11-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# to run it in the background keep it commented out and run it in the terminal
```{r}
# job::job({ rmarkdown::render("/media/Second_stor/wasif/WK_Rprojects/RP_240910_Taste_Genes_Analysis_2/Samples538_D_ML/D1_RF/D1_01.Rmd")}, title = "Running Rmd D1_01 in background")
```

## R Markdown
```{r}
rm(list = ls())
set.seed(23456)
```

# To print the start time
```{r}
start_time = Sys.time()
start_time
```
## File name prefiex

```{r}
file_name_ext = "D1_06_16S_ITS_common_species"

library(ggplot2)
theme_set( theme_minimal(base_family = "Arial") + 
    theme(text = element_text(color = "black")))
```

# Libraries

```{r}
library(dplyr)
library(tibble)
library(ggplot2)
library(stringr)
library(pROC) #ggroc
library(ranger)
library(SIAMCAT)
library(mikropml)
library(progressr)

library(tidymodels)
library(yardstick)
library(lightgbm)
library(bonsai)
library(dials)
library(vip)
library(recipes)
library(ggsci)    # For scientific journal color palettes

# library(PCAtools) # for the command PCAtools::pca
# library(mixOmics)
# library(phyloseq)
# library(microbiome)
# library(PLSDAbatch)
# library(vegan) #varpart
```


# To print the start time
```{r}
start_time = Sys.time()
start_time
```


# for parallelization registeration
```{r}
library(foreach)
library(doParallel)

doFuture::registerDoFuture()
future::plan(future::multisession, workers = 30)
```


## Need three tables
1. A microbiome table


```{r}
# 16S data
Plaque538_16S_Species_CLR_OTU <- 
  read.table(here("Samples538_A_Geno_Microbiome/A2_Maaslin/Maaslin2_16S_Species_output/features",
                  "filtered_data_norm.tsv"),
                      header = T)
Plaque538_16S_Species_CLR_OTU

# ITS data
Plaque538_ITS_Species_CLR_OTU <- 
  read.table(here("Samples538_A_Geno_Microbiome/A2_Maaslin/Maaslin2_ITS_Species_output/features",
                  "filtered_data_norm.tsv"),
                      header = T)
## Combine the two tables
Plaque538_16S_ITS_Species_CLR_OTU = full_join(Plaque538_16S_Species_CLR_OTU,
                                              Plaque538_ITS_Species_CLR_OTU,
                                              by = "feature")

Plaque538_16S_ITS_Species_CLR_OTU_2 = Plaque538_16S_ITS_Species_CLR_OTU %>%
  rename(IID = feature) %>% 
  replace(is.na(.), 0) %>%
  identity()
Plaque538_16S_ITS_Species_CLR_OTU_2
```



## microbiome file with only Maaslin2 significant species

```{r}
# Maaslin2_16S_ITS_features = 
#   read.table(here("../RP_230718_Taste_Genes_Analysis_1/Samples538_Analysis/Microbiome538_files",
#                                             "Maaslin2_16S_ITS_DA_normalized_features.txt"),
#                                        header = T)
# Maaslin2_16S_ITS_features 
# 
# Maaslin2_16S_ITS_features_2 = Maaslin2_16S_ITS_features %>%
#   # column_to_rownames(var = "IID") %>%
#   dplyr::select(-FID) %>% 
#   # as.matrix() %>%
#   filter(IID %in% rownames(Samples538_covariates_vcf_raw)) %>%
#   column_to_rownames(var = "IID") %>% 
#   identity()
# Maaslin2_16S_ITS_features_2 %>% head()
# 
# Maaslin2_16S_ITS_features_names = Maaslin2_16S_ITS_features_2 %>%
#   # column_to_rownames(var = "IID") #%>%
#   colnames()
# Maaslin2_16S_ITS_features_names

```




```{r}
Plaque538_16S_ITS_Species_CLR_OTU_sig = Plaque538_16S_ITS_Species_CLR_OTU_2 %>%
  # dplyr::select(one_of(Maaslin2_16S_ITS_features_names)) %>% 
  identity()
Plaque538_16S_ITS_Species_CLR_OTU_sig

## feature names
Plaque538_16S_ITS_Species_CLR_OTU_sig_names = Plaque538_16S_ITS_Species_CLR_OTU_sig %>% 
  dplyr::select(-IID) %>%
  names()
Plaque538_16S_ITS_Species_CLR_OTU_sig_names %>% head()

```




## load recoded vcf file to make a new vcf which as only the above variants
```{r}
Samples538_recoded_vcf <- 
  read.table(here("Samples538_A_Geno_Microbiome/A1_Plink/A1_00_Plink_files",
                  "Samples538_55gene_Plink.vcf.raw"),
                        header = T)
Samples538_recoded_vcf[, 1:10]  %>% head()


# Create a vector of column names
columns_to_remove <- c("FID", "PAT", "MAT", "SEX", "PHENOTYPE")


Samples538_recoded_vcf_2 = Samples538_recoded_vcf %>%
  column_to_rownames(var = "IID") %>%
  dplyr::select(-c(columns_to_remove)) %>%
  # replace missing values with 0
  mutate(across(everything(), ~if_else(is.na(.), 0, .)))  %>% 
  # to make it a dominant vcf table
  mutate(across(everything(), ~case_when(
  . == 2 ~ 1,  # Replace 2 with 1
  TRUE ~ .     # Keep all other values the same
  ))) %>%
  # change the variants to factor
  mutate(across(everything(), as.factor)) %>%
  ## IID column is required for merging
  # rownames_to_column(var = "IID") %>% 
  identity()

Samples538_recoded_vcf_2 %>% head()
```
## Load the variant file
```{r}
Samples538_Plink_logit_covASPB_w_anno <- 
  read.table(here("Samples538_A_Geno_Microbiome/A1_Plink/A1_02_Plink_dominant",
                  "A1_02_Samples538_55gene_logistic_dominant_cov_anno.txt"),
                                                          header = T)
Samples538_Plink_logit_covASPB_w_anno %>% head()

Samples538_Plink_logit_covASPB_w_anno_2 = Samples538_Plink_logit_covASPB_w_anno %>% 
  # filter(P < 0.001) %>%
  filter(A1 != '*') %>%
  mutate(SNP_A1 = paste(SNP, A1, sep = "_"))
Samples538_Plink_logit_covASPB_w_anno_2 

```

```{r}
Samples538_recoded_vcf_sig = Samples538_recoded_vcf_2 %>%
  dplyr::select(Samples538_Plink_logit_covASPB_w_anno_2$SNP_A1) %>% 
  rownames_to_column(var = "IID")
Samples538_recoded_vcf_sig

## variant names
Samples538_recoded_vcf_sig_names = Samples538_recoded_vcf_sig %>% 
  dplyr::select(-IID) %>%
  names()
Samples538_recoded_vcf_sig_names %>% head()
```


```{r}


```

##covariate

## Load the metadata file
```{r}
Samples538_covariates <- 
  read.table(here("Samples538_A_Geno_Microbiome/A1_Plink/A1_00_Plink_files",
                           "Samples538_Combined_covariates_PCA.txt"),
                      header = T)
Samples538_covariates %>% head()


```


```{r}
Samples538_covariates %>% group_by(Sex) %>% summarise(n = n())
Samples538_covariates %>% group_by(ECC_status) %>% summarise(n = n())
```

Required by plink Binary ('0' = control, '1' = case)
Required by plink Sex code ('1' = male, '2' = female, '0' = unknown)
FID (Family ID) and IID (Individual ID) for it to correctly identify individuals
mbQTL can not take non numerical covariates

```{r}

covariates <- c("Sex", "Age", "Urban_status", "SEFI_score", "PC1", "PC2", "PC3", "PC4", "PC5")

Samples538_covariates_2 = Samples538_covariates %>% 
  dplyr::select(IID, ECC_status, Sex, Age, Urban_status, SEFI_score, PC1, PC2, PC3, PC4, PC5) %>%
  # mutate(FID = IID) %>%
  mutate(Sex = case_when( # AS Original in data 1, Female | 2, Male 
    Sex == 0 ~ "Female",
    Sex == 1 ~ "Male")) %>% 
  mutate(Sex = case_when( # AS 	required by plink Sex code ('1' = male, '2' = female, '0' = unknown)
    Sex == "Female" ~ 2,
    Sex == "Male" ~ 1,
    TRUE ~ 0 )) %>% 
  dplyr::select(IID, ECC_status, covariates) %>%
  mutate(across(c(ECC_status, Sex, Urban_status), as.factor)) %>% 
  # column_to_rownames(var = "IID") %>% 
  identity()

Samples538_covariates_2 


# Samples538_covariates_2_t = Samples538_covariates_2 %>%
#   as.matrix() %>% 
#   t() %>% 
#   as.data.frame()
# Samples538_covariates_2_t 
```










# combine all the datasets


```{r}
# Combine datasets by joining on "IID" and applying transformations in a streamlined manner
Samples538_covariates_vcf_clr_microbiome <- Samples538_covariates_2 %>%
  inner_join(Samples538_recoded_vcf_sig, by = "IID") %>%
  inner_join(Plaque538_16S_ITS_Species_CLR_OTU_2, by = "IID") %>%
  # Remove rows with NA values
  na.omit() %>%
  identity()

Samples538_covariates_vcf_clr_microbiome
```


### Remove the data not required

```{r}
## comment out the line which is required
Samples538_ml_data <- Samples538_covariates_vcf_clr_microbiome %>%
  as_tibble() %>% # to remove the numbered row names
  column_to_rownames("IID") %>% 
  # remove covariates
  dplyr::select(-all_of(covariates)) %>%
  # remove the variants
  dplyr::select(-all_of(Samples538_recoded_vcf_sig_names)) %>%
  # remove microbiome
  # dplyr::select(-all_of(Plaque538_16S_ITS_Species_CLR_OTU_sig_names)) %>%
  identity()
Samples538_ml_data
``` 

# Load the external dataset
```{r}
# Set the folder for the external datasets
dataset_folder <- "Samples538_D_ML/D2_ML_ext_data/Datasets"
dataset_names <- c("Agnello_2017", "Gomez_2017", "Kalpana_2020", "Teng_2015")  # External datasets
# # Define the paths to the phyloseq objects
# phyloseq_files <- list(
#   "Agnello_2017" = here(dataset_folder , "Agnello_2017.rds"),
#   "Gomez_2017" = here(dataset_folder , "Gomez_2017.rds"),
#   "Kalpana_2020" = here(dataset_folder , "Kalpana_2020.rds"),
#   "Teng_2015" = here(dataset_folder , "Teng_2015.rds")
# )

# Initialize a list to store OTU names for each dataset
otu_lists <- list()
```

```{r}
phy_obj <- readRDS(here(dataset_folder, paste0("Agnello_2017", "_ps_CLR_ECCstatus.rds")))
phy_obj
```


```{r}
# Load necessary libraries
library(dplyr)
library(here)

# Define dataset names and folder path
dataset_names <- c("Agnello_2017", "Gomez_2017", "Kalpana_2020", "Teng_2015")
dataset_folder <- here("Samples538_D_ML/D2_ML_ext_data/Datasets")

# Initialize a list to store OTU names
otu_lists <- list()

# Iterate through each dataset to extract OTU names
for (dataset_name in dataset_names) {
  # Load the dataset as a dataframe
  dataset_file <- file.path(dataset_folder, paste0(dataset_name, "_ps_CLR_ECCstatus.rds"))
  data_df <- readRDS(dataset_file)  # Already a dataframe
  
  #remove OTUs where all entries are 0
  data_df <- data_df[, colSums(data_df != 0) > 0]
  
  # Extract OTU column names (assuming these are in columns excluding `sampleid` and `ECC_status`)
  otu_columns <- setdiff(colnames(data_df), c("sampleid", "ECC_status"))
  
  # Store the OTU column names
  otu_lists[[dataset_name]] <- otu_columns
}

# Find the intersection of OTUs across all datasets
common_otus <- Reduce(intersect, otu_lists)

# Print the number of common OTUs
message("Number of common OTUs across all datasets: ", length(common_otus))

# Filter each dataset to retain only common OTUs
filtered_datasets <- list()
for (dataset_name in dataset_names) {
  # Load the dataset again
  dataset_file <- file.path(dataset_folder, paste0(dataset_name, "_ps_CLR_ECCstatus.rds"))
  data_df <- readRDS(dataset_file)
  
  # Retain only the common OTUs and other necessary columns
  filtered_df <- data_df %>%
    dplyr::select(sampleid, ECC_status, all_of(common_otus))
  
  # Store the filtered dataframe
  filtered_datasets[[dataset_name]] <- filtered_df
}

# # Optionally save the filtered datasets
# output_folder <- file.path(dataset_folder, "filtered_datasets")
# dir.create(output_folder, showWarnings = FALSE)
# 
# for (dataset_name in names(filtered_datasets)) {
#   saveRDS(filtered_datasets[[dataset_name]], 
#           file = file.path(output_folder, paste0(dataset_name, "_filtered.rds")))
# }
# 
# message("Filtered datasets saved to: ", output_folder)

# View an example of the filtered dataset
head(filtered_datasets[[1]])


```

## extract common OTUs for the training dataset

```{r}
Samples538_ml_data = Samples538_ml_data %>%
  dplyr::select(ECC_status, any_of(common_otus) ) %>%
  identity()
Samples538_ml_data
```



```{r}
# Set a seed for reproducibility
set.seed(123)

# Splitting the dataset
split <- initial_split(Samples538_ml_data, prop = 0.8)
train_data <- training(split)
test_data <- testing(split)

# Define a recipe for preprocessing
recipe <- recipe(ECC_status ~ ., data = train_data) %>%
          step_nzv(all_predictors())

# Prepare the recipe with training data
prepared_recipe <- prep(recipe, training = train_data)

# Apply the recipe to train and test data
train_data_baked <- bake(prepared_recipe, new_data = train_data)
test_data_baked <- bake(prepared_recipe, new_data = test_data)

# Model specifications with tunable parameters
Ridge_spec <- logistic_reg(penalty = tune(), mixture = 0) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

Lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

SVM_spec <- svm_poly(cost = tune(),
                     degree = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

RandomForest_spec <- rand_forest(
  trees = tune(),
  mtry = tune(),
  min_n = tune()
  ) %>%
  set_engine("ranger", num.threads = 40,
             importance = "impurity") %>%
  set_mode("classification")

# LightGBM_spec <- boost_tree(trees = tune(),
#                         min_n = tune(),
#                         tree_depth = tune(),
#                         learn_rate = tune(),
#                         mtry = tune()
#                         ) %>%
#   set_engine("lightgbm", num_threads = 40) %>%
#   set_mode("classification")

# Cross-validation setup
cv <- vfold_cv(train_data_baked, v = 5, strata = ECC_status)
```


```{r}
# Workflows for each model
workflows <- list(
  Ridge = workflow() %>% add_model(Ridge_spec) %>% add_formula(ECC_status ~ .),
  Lasso = workflow() %>% add_model(Lasso_spec) %>% add_formula(ECC_status ~ .),
  SVM = workflow() %>% add_model(SVM_spec) %>% add_formula(ECC_status ~ .),
  RandomForest = workflow() %>% add_model(RandomForest_spec) %>% add_formula(ECC_status ~ .)#, # remove comma if commenting the next line
  # LightGBM = workflow() %>% add_model(LightGBM_spec) %>% add_formula(ECC_status ~ .)
)

# Define different grid sizes for each model
grid_sizes <- list(
  Ridge = 150,
  Lasso = 150,
  SVM = 150,
  RandomForest = 150 #, # remove comma if commenting the next line
  # LightGBM = 150
)
  # LightGBM with size 10 takes aroung 1.8 hours for 16S train data
```


```{r}
# Set up parallel backend
# registerDoParallel(cores = 20)  # Adjust the number of cores based on your machine

# Tuning each model with parallel processing and timing each process
tuning_results <- list()
tuning_times <- list()

for (model in names(workflows)) {
  start_time <- Sys.time()  # Start timer

  # Extract the model specification from the workflow
  model_spec <- workflows[[model]] %>% pull_workflow_spec()

  if (is.null(model_spec)) {
    stop(paste("The model specification for", model, "is NULL. Please check your workflow setup."))
  }

  # Finalize parameters based on the training data
  params <- parameters(model_spec) %>% finalize(train_data_baked)

  # Create a random grid with the finalized parameters
  grid_randomized <- grid_random(params, size = grid_sizes[[model]])

  tuning_results[[model]] <- tune_grid(
    workflows[[model]],
    resamples = cv,
    grid = grid_randomized,
    # metrics = yardstick::metric_set(pr_auc),
    control = control_grid(save_pred = TRUE, verbose = TRUE)
  )

  end_time <- Sys.time()  # End timer
  tuning_times[[model]] <- end_time - start_time  # Calculate time taken
  print(paste("Time taken for tuning", model, ":", tuning_times[[model]]))
}

# Optional: Stop parallel backend if used
# stopImplicitCluster()
```


```{r}
# Use a lambda function to pass "metric" explicitly
best_params <- map(tuning_results, ~ select_best(.x, metric = "roc_auc"))

# Finalizing models with best parameters
final_models <- map2(workflows, best_params, finalize_workflow)

# Fitting the final models
fits <- map(final_models, fit, data = train_data_baked)

# Predict and evaluate
results <- map_dfr(names(fits), ~{
  preds <- predict(fits[[.x]], test_data_baked, type = "prob")
  bind_cols(preds, test_data_baked, model_id = .x)  # Add model_id column with model names
})

# Now model_id column will have actual model names
# Convert 'ECC_status' to a factor if it's not already
results$ECC_status <- as.factor(results$ECC_status)
# Assuming you have multiple models in 'results'

# Calculate ROC curve for each model separately and bind the results
roc_curve_data <- results %>%
  group_by(model_id) %>%
  group_modify(~roc_curve(.x, truth = ECC_status, .pred_1, event_level = "second")) %>%
  ungroup()
roc_curve_data

# Then, calculate AUROC for each model
auroc_values <- results %>%
  group_by(model_id) %>%
  group_modify(~roc_auc(.x, truth = ECC_status, .pred_1, event_level = "second"), .groups = 'drop') %>%
  ungroup()

# Combine model names with AUROC values
auroc_values <- auroc_values %>%
  mutate(AUROC = .estimate)  %>% 
  dplyr::select(model_id, AUROC)

# Then, calculate AUROC for each model
auprc_values <- results %>%
  group_by(model_id) %>%
  group_modify(~pr_auc(.x, truth = ECC_status, .pred_1, event_level = "second"), .groups = 'drop') %>%
  ungroup()

# Combine model names with AUROC values

auprc_values <- auprc_values %>%
  mutate(AUPRC = .estimate)  %>% 
  dplyr::select(model_id, AUPRC)

auroc_auprc_values =  full_join(auroc_values, auprc_values)
auroc_auprc_values

saveRDS(auroc_auprc_values,
        here("Samples538_D_ML/D1_RF",
             paste0(file_name_ext, "_auroc_auprc_values.rds")
             ))
```


```{r}
# Join this with roc_curve_data
roc_curve_data_2 <- roc_curve_data %>%
  left_join(auroc_auprc_values, by = "model_id") %>% 
  mutate(Model_performance = paste(model_id, "AUROC:", round(AUROC, 3), "AUPRC:", round(AUPRC, 3) ))

# Custom label formatting function
format_ticks <- function(x) {
  ifelse(x == 0, "0", sprintf("%.2f", x))
}


# Plot the ROC curves with AUROC values in the legend
ggplot(roc_curve_data_2, aes(x = 1 - specificity, y = sensitivity, color = Model_performance)) +
  geom_path() +
  coord_equal() +
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0), labels = format_ticks) +  # Custom labels for x-axis
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), labels = format_ticks) +  # Custom labels for y-axis
  labs(title = "16S_ITS_variants_AUROC_Comparison") +
  theme(
    legend.title = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5)  # Add a box around the plot
  ) +
  theme_bw()

ggsave(here("Samples538_D_ML/D1_RF",
            paste0(file_name_ext, "_AUROC_Comparison.png")
             ))

```

## Variable importance

```{r}
# Extract the fitted model from the workflow
RandomForest_fit <- pull_workflow_fit(fits[["RandomForest"]])
  
# Use vip to extract variable importance
VIP_df_RF <- vi(RandomForest_fit,
                     num_features = 20L,
                     geom = "col")
VIP_df_RF

VIP_df_RF = VIP_df_RF %>% 
  mutate(Relative_importance = Importance / max(Importance)) %>% 
   head(15) %>% 
  mutate(Variable = factor(Variable, levels = unique(rev(Variable)))) 


saveRDS(VIP_df_RF, here("Samples538_D_ML/D1_RF",
                        paste0(file_name_ext, "_VIP_RF.rds")
             ))


VIP_df_RF_ggplot =
ggplot(VIP_df_RF, aes(y = Variable, x = Relative_importance)) +
    geom_bar(stat = "identity", fill = "mediumpurple4", alpha = 0.9, color = "mediumpurple4") +
  labs(x = "Relative Variable Importance", y = "All Features", title = "Variable_importance") +
  scale_y_discrete(labels = function(x) abbreviate(x, minlength = 40)) +
  theme_bw() +
    theme(
    text = element_text(colour = "black"),
    axis.title = element_text(size = 11),
    # axis.title.y = element_blank(), # Hide the y-axis title
    axis.text = element_text(size = 8),
    axis.text.y = element_text(colour = "black"),
    axis.ticks.y = element_blank(), # Hide y-axis ticks
    axis.ticks.x = element_blank(), # Hide x-axis ticks if desired
    # panel.grid.major = element_blank(), # Remove major grid lines
    # panel.grid.minor = element_blank(), # Remove minor grid lines
    panel.background = element_blank(), # Remove panel background
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 9),
    plot.title = element_blank(),
    legend.position = "bottom",
    axis.line.x = element_line(color="black"), # Keep x-axis line
    axis.line.y = element_line(color="black") # 
  ) 
VIP_df_RF_ggplot

ggsave(here("Samples538_D_ML/D1_RF",
            paste0(file_name_ext, "_VIP_plot.png")
             ),
       height = 10, width = 10)

```


## Apply each model on the external dataset
# Load the external dataset
```{r}
# Initialize an empty list to store the results for all models and datasets
results_list <- list()

# Define model names and dataset names
model_names <- names(fits)  # List of model names (keys of the fits list)
dataset_names <- c("Agnello_2017", "Gomez_2017", "Kalpana_2020", "Teng_2015")  # External datasets

# Set the folder for the external datasets
dataset_folder <- here("Samples538_D_ML/D2_ML_ext_data/Datasets")  # Folder where the external dataset is stored

# Iterate over each model and dataset
for (model_name in model_names) {
  model <- fits[[model_name]]  # Get the model from the fits list
  
  # Iterate over each external dataset
  for (dataset_name in dataset_names) {
    
    # Load the external dataset (make sure the file exists)
    dataset_file <- file.path(dataset_folder, paste0(dataset_name, "_ps_CLR_ECCstatus.rds"))
    if (!file.exists(dataset_file)) {
      next  # Skip this iteration if the file doesn't exist
    }
    
    # Read the external dataset
    external_data <- readRDS(dataset_file)
    
    # Ensure the target variable 'ECC_status' is a factor
    external_data$ECC_status <- as.factor(external_data$ECC_status)
    
    # Extract the predictor columns from the training data (i.e., predictor variables)
    required_columns <- colnames(train_data)  # Get all column names from the training data (predictors)
    
    # Add missing columns (in case any predictors are missing in external_data) with NA values
    missing_columns <- setdiff(required_columns, colnames(external_data))
    if (length(missing_columns) > 0) {
      external_data[missing_columns] <- 0
      message(paste("Added missing columns:", paste(missing_columns, collapse = ", ")))
    }
    
    # Remove any columns from external_data that are not in the required_columns (i.e., keep only the predictors)
    external_data <- external_data[, required_columns, drop = FALSE]
    
    # Apply the recipe to the external dataset (ensure it's baked)
    baked_data <- bake(prepared_recipe, new_data = external_data)
    
    # Predict probabilities using the fitted model
    preds <- predict(model, baked_data, type = "prob")
    
    # Combine the predictions with the external dataset and model name
    result <- bind_cols(preds, external_data, model_id = model_name, dataset_id = dataset_name)
    
    # Calculate AUROC
    auroc_result <- roc_auc(result, truth = ECC_status, .pred_1, event_level = "second")
    
    # Calculate AUPRC
    auprc_result <- pr_auc(result, truth = ECC_status, .pred_1, event_level = "second")
    
    # Create a summary row for the results
    summary_result <- tibble(
      model_id = model_name,
      dataset_id = dataset_name,
      AUROC = auroc_result$.estimate,
      AUPRC = auprc_result$.estimate
    )
    
    # Add the summary result to the results list
    results_list[[paste0(model_name, "_", dataset_name)]] <- summary_result
  }
}

# Combine all results into one data frame
final_results <- bind_rows(results_list)

# Print the final results
print(final_results)

#  save the results to an RDS file
saveRDS(final_results, file = here("Samples538_D_ML/D1_RF", "ext_datasets_arroc_auprc_results.rds"))

```


## ggplot for external dataset results

```{r}
# Read the data
ext_datasets_arroc_auprc_results = readRDS(here("Samples538_D_ML/D1_RF", "ext_datasets_arroc_auprc_results.rds"))

# Reshape the data to have AUROC and AUPRC in the same column with an additional 'Metric' column
long_results <- ext_datasets_arroc_auprc_results %>%
  pivot_longer(cols = c(AUROC, AUPRC), 
               names_to = "Metric", 
               values_to = "Value")
long_results

# Plot with facets for AUROC and AUPRC, applying a color palette from ggsci
ggplot(long_results, aes(x = model_id, y = Value, fill = dataset_id, width=.7)) +
    geom_bar(stat = "identity", position = "dodge", alpha = 0.8, color = "black") +
  facet_wrap(~ Metric, scales = "free_y") +  # Create a facet for AUROC and AUPRC
  theme_bw() +
  labs(title = "Model Performance Across Datasets", 
       x = "Model", 
       y = "Model Performance",
       fill = "Datasets") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, color = "black"),  # Black x-axis labels, rotated for readability
    axis.text.y = element_text(color = "black"),                         # Black y-axis labels
    axis.title = element_text(color = "black", face = "bold"),           # Bold axis titles for emphasis
    plot.title = element_text(hjust = 0.5, face = "bold", color = "black"), # Centered, bold, black title
    # panel.grid = element_blank(),                                        # Remove grid lines for cleaner look
    panel.border = element_rect(color = "black", fill = NA)   ,           # Add black border around plot
        axis.ticks = element_blank()
        ) +  # Rotate x-axis labels for better readability
  scale_y_continuous(breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),
                     limits = c(0, 1),
                     expand = c(0, 0)) +  # Custom breaks and limits
  scale_fill_nejm()  # Apply a Lancet-inspired color palette from ggsci


ggsave(here("Samples538_D_ML/D1_RF",
            paste0(file_name_ext, "ext_datasets_AUROC_AUPRC_Comparison.jpg")
             ),
       width = 9, height = 4.5, dpi = 300)

```

```{r}
# Reshape the data to have AUROC and AUPRC in the same column with an additional 'Metric' column
long_results <- ext_datasets_arroc_auprc_results %>%
  pivot_longer(cols = c(AUROC, AUPRC), 
               names_to = "Metric", 
               values_to = "Value") %>% 
  filter(model_id == "RandomForest") %>% 
  mutate(dataset_id = factor(dataset_id))

# Plot with facets for AUROC and AUPRC, applying a color palette from ggsci
ggplot(long_results, aes(y = dataset_id, x = Value, fill = Metric, , width=.7)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, color = "black") +
  theme_minimal(base_family = "Arial") +  # Set base font to Arial and minimal theme for a clean look
  labs(
    # title = "Model Performance (AUROC and AUPRC) Across Datasets", 
       y = "Dataset", 
       x = "Model Performance",
       fill = "Performance\nMetric"
       ) +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 0, color = "black", family = "Arial"),  # Black x-axis labels, rotated for readability
    axis.text.y = element_text(color = "black"),                         # Black y-axis labels
    axis.title = element_text(color = "black", face = "bold"),           # Bold axis titles for emphasis
    plot.title = element_text(hjust = 0.5, face = "bold", color = "black"), # Centered, bold, black title
    # panel.grid = element_blank(),                                        # Remove grid lines for cleaner look
    panel.border = element_rect(color = "black", fill = NA),              # Add black border around plot
    legend.position = "top",                                             # Position legend at the top
  ) +
  scale_x_continuous(breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),
                     limits = c(0, 1),
                     expand = c(0, 0)) +  # Custom breaks and limits
  scale_y_discrete(limits = rev(levels(long_results$dataset_id))) +  # Reverse y-axis order
  scale_fill_simpsons()  # Apply "Simpsons" color palette from ggsci

# Save the plot as a high-quality PNG image
ggsave(here("Samples538_D_ML/D1_RF",
            paste0(file_name_ext, "ext_datasets_AUROC_AUPRC_Comparison_RF.jpg")),
       width = 4.5, height = 3.5, dpi = 300)


```



